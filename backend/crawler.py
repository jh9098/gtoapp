import requests
from bs4 import BeautifulSoup
import re
import urllib3
import asyncio
import time

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

MAIN_URL = "https://gto.shopreview.co.kr/usr"
CAMPAIGN_URL_TEMPLATE = "https://gto.shopreview.co.kr/usr/campaign_detail?csq={}"

def get_public_campaigns(session):
    public_campaigns = set()
    for attempt in range(3):
        try:
            response = session.get(MAIN_URL, verify=False, timeout=10)
            response.raise_for_status()
            scripts = BeautifulSoup(response.text, "html.parser").find_all("script")
            for script in scripts:
                matches = re.findall(r'data-csq=["\']?(\d+)', script.text)
                public_campaigns.update(map(int, matches))
            if public_campaigns:
                return public_campaigns
        except requests.exceptions.RequestException:
            time.sleep(3)
    return set()

def fetch_campaign_data(campaign_id, session, public_campaigns, selected_days, exclude_keywords):
    url = CAMPAIGN_URL_TEMPLATE.format(campaign_id)
    try:
        response = session.get(url, verify=False, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        if soup.find("script", string="window.location.href = '/usr/login_form';"):
            return None

        participation_time = soup.find("button", class_="butn butn-success", disabled=True)
        participation_time = participation_time.text.strip() if participation_time else ""
        if "ì‹œì—" in participation_time:
            participation_time = participation_time.replace("ì‹œì—", "ì‹œ 00ë¶„ì—")

        product_name_tag = soup.find("h3")
        product_name = product_name_tag.text.strip().replace("&", "") if product_name_tag else "ìƒí’ˆëª… ì—†ìŒ"

        #print(f"ğŸ” ìº í˜ì¸ {campaign_id} ì°¸ì—¬ ì‹œê°„: {participation_time}")
        #print(f"ğŸ” ìƒí’ˆëª…: {product_name}")

        day_match = re.search(r"(\d{2})ì¼", participation_time)
        if not day_match or day_match.group(0) not in selected_days:
            return None

        if soup.find("button", string="ì¢…ë£Œëœ ìº í˜ì¸ ì…ë‹ˆë‹¤") or \
           soup.find("div", id="alert_msg", string="í•´ë‹¹ ìº í˜ì¸ì€ ì°¸ì—¬ê°€ ë¶ˆê°€ëŠ¥í•œ ìƒíƒœì…ë‹ˆë‹¤.") or \
           soup.find("button", string="ì°¸ì—¬ ê°€ëŠ¥ ì‹œê°„ì´ ì•„ë‹™ë‹ˆë‹¤") or \
           soup.find("button", string="ìº í˜ì¸ ì°¸ì—¬"):
            return None

        if any(keyword in product_name for keyword in exclude_keywords):
            return None

        price = "ê°€ê²© ì •ë³´ ì—†ìŒ"
        price_tag = soup.find(string=re.compile("ì´ ê²°ì œê¸ˆì•¡"))
        if price_tag:
            price_text = price_tag.find_next("div", style="text-align:right")
            if price_text:
                price_value = re.sub(r"[^\d]", "", price_text.text)
                price = price_value if price_value else price

        product_type = "ìƒí’ˆêµ¬ë¶„ ì—†ìŒ"
        for section in soup.find_all("div", class_="row col-sm4 col-12"):
            title = section.find("div", class_="col-6")
            value = section.find("div", style="text-align:right")
            if title and value and "ë°°ì†¡" in title.text:
                product_type = value.text.strip()
                break

        shop_name = "ì‡¼í•‘ëª° ì •ë³´ ì—†ìŒ"
        shop_section = soup.find("div", class_="col-sm-9")
        if shop_section:
            shop_img = shop_section.find("img")
            if shop_img and "alt" in shop_img.attrs:
                shop_name = shop_img["alt"].strip()

        text_review = "í¬í†  ë¦¬ë·°"
        if soup.find("label", string="í…ìŠ¤íŠ¸ ë¦¬ë·°"):
            text_review = "í…ìŠ¤íŠ¸ ë¦¬ë·°"

        if price != "ê°€ê²© ì •ë³´ ì—†ìŒ":
            price_num = int(price)
            if "ê¸°íƒ€ë°°ì†¡" in product_type and "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´" in shop_name and price_num < 90000:
                return None
            if "ê¸°íƒ€ë°°ì†¡" in product_type and "ì¿ íŒ¡" in shop_name and price_num < 28500:
                return None
            if "ì‹¤ë°°ì†¡" in product_type and price_num < 8500:
                return None

        result = f"{product_type} & {text_review} & {shop_name} & {price} & {participation_time} & {product_name} & {url}"
        return (None, result) if campaign_id in public_campaigns else (result, None)
        print(f"ê²°ê³¼ {result}")
    except requests.exceptions.RequestException:
        return None

async def run_crawler_streaming(session_cookie, selected_days, exclude_keywords,
                                use_full_range=True, start_id=None, end_id=None, exclude_ids=None):
    session = requests.Session()
    session.cookies.set("PHPSESSID", session_cookie)

    if exclude_ids is None:
        exclude_ids = set()

    public_campaigns = get_public_campaigns(session)
    if not public_campaigns:
        yield {"event": "error", "data": "ê³µê°œ ìº í˜ì¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
        return

    if use_full_range:
        start_id = min(public_campaigns)
        end_id = max(public_campaigns)
    else:
        if start_id is None or end_id is None:
            yield {"event": "error", "data": "ìˆ˜ë™ ë²”ìœ„ ì‚¬ìš© ì‹œ start_id, end_idëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤."}
            return

    print(f"ğŸ“¡ ì‹¤í–‰í•  ìº í˜ì¸ ë²”ìœ„: {start_id} ~ {end_id}")

    for cid in range(start_id, end_id + 1):
        if cid in exclude_ids:
            continue

        result = await asyncio.to_thread(
            fetch_campaign_data,
            cid, session, public_campaigns, selected_days, exclude_keywords
        )
        if result:
            h, p = result
            if h:
                yield {"event": "hidden", "data": h}
            if p:
                yield {"event": "public", "data": p}

    yield {"event": "done", "data": "í¬ë¡¤ë§ ì™„ë£Œ"}

